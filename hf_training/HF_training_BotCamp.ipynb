{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HF_training_BotCamp.ipynb","provenance":[{"file_id":"1WycNeRGfvMeNsZ5zwcUvTCyikrKWXivW","timestamp":1643115682450}],"collapsed_sections":["qdomidXONkLi","5r9nGQs-RdYJ"],"mount_file_id":"1WycNeRGfvMeNsZ5zwcUvTCyikrKWXivW","authorship_tag":"ABX9TyPhcDNtuph6DE7AAswtgzNe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8e463232c0114eb1aa21f93b1c11d0c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c4f2dd6f84bb4dde9bce8f311167e268","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e0484da40e594ebaa9c67396bd79e5d6","IPY_MODEL_2564eef01ffd413c88d9de62e6021f3b","IPY_MODEL_1ed14d0d86874bd59a9113db24c9b625"]}},"c4f2dd6f84bb4dde9bce8f311167e268":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0484da40e594ebaa9c67396bd79e5d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_66bceacd03b64355847898f7f54a9799","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_72c40270959b436eae7650ae76df8328"}},"2564eef01ffd413c88d9de62e6021f3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5bff33ef6f8f42258bbbff368b2fe2d1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bed138ad18fe47ba8f1b333de74ef2bc"}},"1ed14d0d86874bd59a9113db24c9b625":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8e4dba2f1e0241129dc90b733deb0184","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00, 20.31ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07a152fa351e4f91ae088c36376108d0"}},"66bceacd03b64355847898f7f54a9799":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"72c40270959b436eae7650ae76df8328":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5bff33ef6f8f42258bbbff368b2fe2d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bed138ad18fe47ba8f1b333de74ef2bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e4dba2f1e0241129dc90b733deb0184":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"07a152fa351e4f91ae088c36376108d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NeZVY3lE5-FZ"},"outputs":[],"source":["!pip install transformers\n","!pip install datasets"]},{"cell_type":"code","source":["!pwd\n","% cd /content/drive/MyDrive/your_path_to_the_dir\n","!ls"],"metadata":{"id":"e_5pcJBq6JVp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","from transformers import AutoTokenizer, DataCollatorWithPadding\n","from transformers import TrainingArguments\n","from transformers import AutoModelForSequenceClassification\n","from transformers import Trainer"],"metadata":{"id":"TMyBRPHXHEFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Load data\n","campus_dataset = load_dataset(\"csv\", data_files=\"enhanced_questions_int.csv\")\n","\n","#train and test\n","campus_dataset = campus_dataset[\"train\"].train_test_split(train_size=0.9, seed=45)"],"metadata":{"id":"pQX0_WYV6IT2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["campus_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKCBlOmVAF07","executionInfo":{"status":"ok","timestamp":1638963420217,"user_tz":-60,"elapsed":124,"user":{"displayName":"Andres Sabatel Roloff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioriXidbcxgN1P47F1Qyu1wbRQgSVRMh4C_WUtqg=s64","userId":"10380306212479632136"}},"outputId":"578f488a-73ea-432a-d46b-a3cb656a01e2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['labels', 'text'],\n","        num_rows: 524\n","    })\n","    test: Dataset({\n","        features: ['labels', 'text'],\n","        num_rows: 59\n","    })\n","})"]},"metadata":{},"execution_count":113}]},{"cell_type":"code","source":["#Save in arrow format\n","\n","campus_dataset.save_to_disk('campus_questions_dataset')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aZtB5w23FPtT","executionInfo":{"status":"ok","timestamp":1638963433048,"user_tz":-60,"elapsed":372,"user":{"displayName":"Andres Sabatel Roloff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioriXidbcxgN1P47F1Qyu1wbRQgSVRMh4C_WUtqg=s64","userId":"10380306212479632136"}},"outputId":"0112798c-d352-40b1-c821-e845834da5d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5f3e9ec34791bff8/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-875dc06d58f49fcd.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5f3e9ec34791bff8/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-bb37941d3a865b65.arrow\n"]}]},{"cell_type":"markdown","source":["# Creating checkpoints"],"metadata":{"id":"GCyTrPbdEmZu"}},{"cell_type":"code","source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPxZRNqwEnci","executionInfo":{"status":"ok","timestamp":1638963439318,"user_tz":-60,"elapsed":3453,"user":{"displayName":"Andres Sabatel Roloff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioriXidbcxgN1P47F1Qyu1wbRQgSVRMh4C_WUtqg=s64","userId":"10380306212479632136"}},"outputId":"33339a9b-bcb3-43ee-f709-cfa2975a1b5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n"]}]},{"cell_type":"code","source":["def tokenize_function(example):\n","    return tokenizer(example[\"text\"], truncation=True)\n","\n","\n","tokenized_datasets = campus_dataset.map(tokenize_function, batched=True)\n","tokenized_datasets.set_format(\"torch\")\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","#tokenized_datasets = tokenized_datasets.rename_column('labels', 'labels')\n","tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["8e463232c0114eb1aa21f93b1c11d0c5","c4f2dd6f84bb4dde9bce8f311167e268","e0484da40e594ebaa9c67396bd79e5d6","2564eef01ffd413c88d9de62e6021f3b","1ed14d0d86874bd59a9113db24c9b625","66bceacd03b64355847898f7f54a9799","72c40270959b436eae7650ae76df8328","5bff33ef6f8f42258bbbff368b2fe2d1","bed138ad18fe47ba8f1b333de74ef2bc","8e4dba2f1e0241129dc90b733deb0184","07a152fa351e4f91ae088c36376108d0"]},"id":"mMNxjkgO-yaS","executionInfo":{"status":"ok","timestamp":1638963446083,"user_tz":-60,"elapsed":698,"user":{"displayName":"Andres Sabatel Roloff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioriXidbcxgN1P47F1Qyu1wbRQgSVRMh4C_WUtqg=s64","userId":"10380306212479632136"}},"outputId":"3c8a114b-33e0-4859-a37f-f037bce05988"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-5f3e9ec34791bff8/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a/cache-1d3a11cdd2c42964.arrow\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e463232c0114eb1aa21f93b1c11d0c5","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{}}]},{"cell_type":"code","source":["tokenized_datasets['train']\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39wfIEae_0pT","executionInfo":{"status":"ok","timestamp":1638963453547,"user_tz":-60,"elapsed":666,"user":{"displayName":"Andres Sabatel Roloff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioriXidbcxgN1P47F1Qyu1wbRQgSVRMh4C_WUtqg=s64","userId":"10380306212479632136"}},"outputId":"314879a5-0811-4381-aee6-842445272681"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n","    num_rows: 524\n","})"]},"metadata":{},"execution_count":117}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","train_dataloader = DataLoader(\n","    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",")\n","eval_dataloader = DataLoader(\n","    tokenized_datasets[\"test\"], batch_size=8, collate_fn=data_collator\n",")"],"metadata":{"id":"MP49BD4wLOfm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Metrics"],"metadata":{"id":"CtXBaVtjeCBe"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","def compute_metrics(pred):\n","  labels = pred.label_ids\n","  preds = pred.predictions.argmax(-1)\n","  # calculate accuracy using sklearn's function\n","  acc = accuracy_score(labels, preds)\n","  return {\n","#      'accuracy': acc,\n","  }"],"metadata":{"id":"wfna3JgreFjt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training\n"],"metadata":{"id":"SaGymBIOGns6"}},{"cell_type":"code","source":["training_args = TrainingArguments(\"test-trainer\")\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',          # output directory\n","    num_train_epochs=5,              # total number of training epochs\n","    per_device_train_batch_size=8,  # batch size per device during training\n","    per_device_eval_batch_size=20,   # batch size for evaluation\n","    warmup_steps=100,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n","    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n","    logging_steps=50,               # log & save weights each logging_steps\n","    save_steps=500,\n","    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",")\n","\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=6)\n","\n","training_args"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pp7tfXheGnJL","executionInfo":{"status":"ok","timestamp":1638963469645,"user_tz":-60,"elapsed":2696,"user":{"displayName":"Andres Sabatel Roloff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioriXidbcxgN1P47F1Qyu1wbRQgSVRMh4C_WUtqg=s64","userId":"10380306212479632136"}},"outputId":"c9087db9-f40c-490b-b057-0d83ee1bbd27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","using `logging_steps` to initialize `eval_steps` to 50\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.12.5\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=False,\n","eval_accumulation_steps=None,\n","eval_steps=50,\n","evaluation_strategy=IntervalStrategy.STEPS,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","hub_model_id=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=./logs,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=50,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=5,\n","output_dir=./results,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=20,\n","per_device_train_batch_size=8,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=./results,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=IntervalStrategy.STEPS,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=100,\n","weight_decay=0.01,\n","xpu_backend=None,\n",")"]},"metadata":{},"execution_count":120}]},{"cell_type":"code","source":["trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    compute_metrics = compute_metrics,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n",")"],"metadata":{"id":"-Wt780lRHQ-d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":855},"id":"nC0u2aSrIMGT","executionInfo":{"status":"ok","timestamp":1638963514325,"user_tz":-60,"elapsed":26319,"user":{"displayName":"Andres Sabatel Roloff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioriXidbcxgN1P47F1Qyu1wbRQgSVRMh4C_WUtqg=s64","userId":"10380306212479632136"}},"outputId":"405096c1-69c6-4be3-ac25-18fb103f0026"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 524\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 330\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [330/330 00:26, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.631000</td>\n","      <td>1.315421</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.772600</td>\n","      <td>0.184475</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.074700</td>\n","      <td>0.012884</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.011000</td>\n","      <td>0.005385</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.004800</td>\n","      <td>0.003323</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.003900</td>\n","      <td>0.002880</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 59\n","  Batch size = 20\n","***** Running Evaluation *****\n","  Num examples = 59\n","  Batch size = 20\n","***** Running Evaluation *****\n","  Num examples = 59\n","  Batch size = 20\n","***** Running Evaluation *****\n","  Num examples = 59\n","  Batch size = 20\n","***** Running Evaluation *****\n","  Num examples = 59\n","  Batch size = 20\n","***** Running Evaluation *****\n","  Num examples = 59\n","  Batch size = 20\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=330, training_loss=0.37878330887267087, metrics={'train_runtime': 26.75, 'train_samples_per_second': 97.944, 'train_steps_per_second': 12.336, 'total_flos': 17039108316816.0, 'train_loss': 0.37878330887267087, 'epoch': 5.0})"]},"metadata":{},"execution_count":122}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"xyF3ki0QmJ2y"}},{"cell_type":"code","source":["trainer.evaluate()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":184},"id":"Gcnf8keHdk-A","executionInfo":{"status":"ok","timestamp":1638963520716,"user_tz":-60,"elapsed":665,"user":{"displayName":"Andres Sabatel Roloff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioriXidbcxgN1P47F1Qyu1wbRQgSVRMh4C_WUtqg=s64","userId":"10380306212479632136"}},"outputId":"858c8f43-8283-44a0-b223-2d876e9c5f33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 59\n","  Batch size = 20\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3/3 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 5.0,\n"," 'eval_loss': 0.0028184857219457626,\n"," 'eval_runtime': 0.1039,\n"," 'eval_samples_per_second': 567.976,\n"," 'eval_steps_per_second': 28.88}"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["#save the model\n","\n","model_path = \"botcamp-bert-base-uncased\"\n","model.save_pretrained(model_path)\n","tokenizer.save_pretrained(model_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PwOdmVsXcqGk","executionInfo":{"status":"ok","timestamp":1638963552324,"user_tz":-60,"elapsed":2762,"user":{"displayName":"Andres Sabatel Roloff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioriXidbcxgN1P47F1Qyu1wbRQgSVRMh4C_WUtqg=s64","userId":"10380306212479632136"}},"outputId":"8e999c01-68fa-488f-839c-4613609cf400"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Configuration saved in botcamp-bert-base-uncased/config.json\n","Model weights saved in botcamp-bert-base-uncased/pytorch_model.bin\n","tokenizer config file saved in botcamp-bert-base-uncased/tokenizer_config.json\n","Special tokens file saved in botcamp-bert-base-uncased/special_tokens_map.json\n"]},{"output_type":"execute_result","data":{"text/plain":["('botcamp-bert-base-uncased/tokenizer_config.json',\n"," 'botcamp-bert-base-uncased/special_tokens_map.json',\n"," 'botcamp-bert-base-uncased/vocab.txt',\n"," 'botcamp-bert-base-uncased/added_tokens.json',\n"," 'botcamp-bert-base-uncased/tokenizer.json')"]},"metadata":{},"execution_count":124}]},{"cell_type":"code","source":["def get_prediction(text):\n","    # prepare our text into tokenized sequence\n","    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n","    # perform inference to our model\n","    outputs = model(**inputs)\n","    # get output probabilities by doing softmax\n","    probs = outputs[0].softmax(1)\n","    # executing argmax function to get the candidate label\n","    return probs, probs.argmax()"],"metadata":{"id":"ovqmhDs-cxID"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = \"I want to eat. \"\n","print(get_prediction(text))\n","t, p = get_prediction(text)\n","p.item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aa3d-9Ihc2yl","executionInfo":{"status":"ok","timestamp":1638963681859,"user_tz":-60,"elapsed":372,"user":{"displayName":"Andres Sabatel Roloff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioriXidbcxgN1P47F1Qyu1wbRQgSVRMh4C_WUtqg=s64","userId":"10380306212479632136"}},"outputId":"361e437b-b5c2-4bfc-f2fd-b9351c87ae92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[2.5115e-04, 3.4493e-04, 9.9836e-01, 3.8031e-04, 3.9956e-04, 2.6372e-04]],\n","       device='cuda:0', grad_fn=<SoftmaxBackward0>), tensor(2, device='cuda:0'))\n"]},{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":134}]}]}